---
title: "Homework 2"
author: "Ziyi Fang"
output:
    html_document:
      toc: true
      toc_float: true
      code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## Linear Regression

For this lab, we will be working with a data set from the UCI (University of California, Irvine) Machine Learning repository ([see website here](http://archive.ics.uci.edu/ml/datasets/Abalone)). The full data set consists of $4,177$ observations of abalone in Tasmania. (Fun fact: [Tasmania](https://en.wikipedia.org/wiki/Tasmania "Tasmania") supplies about $25\%$ of the yearly world abalone harvest.)

![*Fig 1. Inside of an abalone shell.*](https://cdn.shopify.com/s/files/1/1198/8002/products/1d89434927bffb6fd1786c19c2d921fb_2000x_652a2391-5a0a-4f10-966c-f759dc08635c_1024x1024.jpg?v=1582320404){width="152"}

The age of an abalone is typically determined by cutting the shell open and counting the number of rings with a microscope. The purpose of this data set is to determine whether abalone age (**number of rings + 1.5**) can be accurately predicted using other, easier-to-obtain information about the abalone.

The full abalone data set is located in the `\data` subdirectory. Read it into *R* using `read_csv()`. Take a moment to read through the codebook (`abalone_codebook.txt`) and familiarize yourself with the variable definitions.

Make sure you load the `tidyverse` and `tidymodels`!

```{r}
library(tidyverse)
library(tidymodels)
library(recipes)
library(rsample)
library(parsnip)
```

```{r}
setwd("~/Desktop")
abalone<- read_csv("abalone.csv")
```


### Question 1

Your goal is to predict abalone age, which is calculated as the number of rings plus 1.5. Notice there currently is no `age` variable in the data set. Add `age` to the data set.

Assess and describe the distribution of `age`.

```{r, addAge}
abalone <- abalone %>% mutate(age = rings + 1.5)
summary(abalone$age)
sd(abalone$age)
ggplot(abalone, aes(x = age)) + geom_histogram(fill = "lightblue") + 
  theme_classic() +
  labs(title = "Distribution of Age")
#Distribution of age is roughly normally distributed, slightly skewed
#mean is 11.43, standard devition is 3.22
```

### Question 2

Split the abalone data into a training set and a testing set. Use stratified sampling. You should decide on appropriate percentages for splitting the data.

*Remember that you'll need to set a seed at the beginning of the document to reproduce your results.*

```{r}
set.seed(468)

abalone_split<- initial_split(abalone, strata = age, prop = .8)
train<- training(abalone_split)
test<- testing(abalone_split)

```


### Question 3

Using the **training** data, create a recipe predicting the outcome variable, `age`, with all other predictor variables. Note that you should not include `rings` to predict `age`. Explain why you shouldn't use `rings` to predict `age`.

Steps for your recipe:

1.  dummy code any categorical predictors

2.  create interactions between

    -   `type` and `shucked_weight`,
    -   `longest_shell` and `diameter`,
    -   `shucked_weight` and `shell_weight`

3.  center all predictors, and

4.  scale all predictors.

You'll need to investigate the `tidymodels` documentation to find the appropriate step functions to use.

```{r}
#You should not use rings to predict age because age is a function of rings. You would be able to create a model that would perfectly predict age if you used rings as an input. 

train<- train %>% dplyr::select(-c('rings'))
```

```{r}

abalone_recipe<- recipe(age ~ ., data = train) %>% 
  step_interact(terms =  ~ type:shucked_weight) %>% 
  step_interact(terms =  ~ longest_shell:diameter) %>% 
  step_interact(terms =  ~ shucked_weight:shell_weight) %>% 
  step_center(all_numeric(), -age) %>% 
  step_scale(all_numeric(), -age) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  update_role(type, new_role = "predictor") %>% 
  prep(training = train) %>% 
  prep()

#train_prep<- prep(abalone_recipe, training = train)
#train_final<- bake(train_prep, train)

#test_prep<- prep(abalone_recipe, training = test)
#test_final<- bake(train_prep,  test)

```


### Question 4

Create and store a linear regression object using the `"lm"` engine.

```{r}
lm_model<- linear_reg() %>% set_engine("lm") %>% set_mode("regression")
```


### Question 5

Now:

1.  set up an empty workflow,
2.  add the model you created in Question 4, and
3.  add the recipe that you created in Question 3.

```{r}
lm_wflow<- workflow() %>% 
  add_recipe(abalone_recipe) %>% 
  add_model(lm_model)
```


### Question 6

Use your `fit()` object to predict the age of a hypothetical female abalone with longest_shell = 0.50, diameter = 0.10, height = 0.30, whole_weight = 4, shucked_weight = 1, viscera_weight = 2, shell_weight = 1.

```{r}
test<- test %>% select(-c(rings))
df = data.frame(type = c("F","M","I"), longest_shell = c(0.50, .50, .10), diameter = c(0.10, .10,.10), height = c(0.30, .30,.30), whole_weight = c(4, 4,4 ), shucked_weight = c(1,1,1 ), viscera_weight = c(2,2,2), shell_weight = c(1,1,1))
lm_fit<-  fit(lm_wflow,data =  train)
lm_predict<- predict(lm_fit,new_data = test)
lm_predict_train<- predict(lm_fit,new_data = train)
newObsPrediction<- predict(lm_fit,new_data = df)
```


### Question 7

Now you want to assess your model's performance. To do this, use the `yardstick` package:

1.  Create a metric set that includes *R^2^*, RMSE (root mean squared error), and MAE (mean absolute error).
2.  Use `predict()` and `bind_cols()` to create a tibble of your model's predicted values from the **training data** along with the actual observed ages (these are needed to assess your model's performance).
3.  Finally, apply your metric set to the tibble, report the results, and interpret the *R^2^* value.

```{r}
age_metrics<- metric_set(rmse,mae,rsq)
#tibble of actual and predictions for training data
df2<- tibble(actuals = train$age, predictions = lm_predict_train %>% as_vector())
df2 %>% age_metrics(truth = actuals, estimate = predictions)
# Rsq is equal to 0,5568951, which indicates that about half of the variability in the outcome data cannot be explained by the model.
```


### Required for 231 Students

In lecture, we presented the general bias-variance tradeoff, which takes the form:

$$
E[(y_0 - \hat{f}(x_0))^2]=Var(\hat{f}(x_0))+[Bias(\hat{f}(x_0))]^2+Var(\epsilon)
$$

where the underlying model $Y=f(X)+\epsilon$ satisfies the following:

- $\epsilon$ is a zero-mean random noise term and $X$ is non-random (all randomness in $Y$ comes from $\epsilon$);
- $(x_0, y_0)$ represents a test observation, independent of the training set, drawn from the same model;
- $\hat{f}(.)$ is the estimate of $f$ obtained from the training set.

#### Question 8

Which term(s) in the bias-variance tradeoff above represent the reproducible error? Which term(s) represent the irreducible error?

#### Question 9

Using the bias-variance tradeoff above, demonstrate that the expected test error is always at least as large as the irreducible error.

#### Question 10

Prove the bias-variance tradeoff.

Hints:

- use the definition of $Bias(\hat{f}(x_0))=E[\hat{f}(x_0)]-f(x_0)$;
- reorganize terms in the expected test error by adding and subtracting $E[\hat{f}(x_0)]$